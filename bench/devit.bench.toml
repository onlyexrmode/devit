[backend]
kind = "openai_like"
# ajuste selon ton setup :
base_url = "http://localhost:1234/v1"   # LM Studio
# base_url = "http://localhost:11434/v1" # Ollama (fallback /api/chat géré dans le backend)
model = "llama3:8b"
api_key = ""

[policy]
approval = "never"             # pas d'interaction en bench
sandbox  = "workspace-write"   # autoriser l'écriture dans le workspace

[sandbox]
cpu_limit = 2
mem_limit_mb = 4096
net = "off"

[git]
conventional = true
max_staged_files = 100
